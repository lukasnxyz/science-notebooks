{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4191f276-4074-49e7-863f-6f016252bc69",
   "metadata": {},
   "source": [
    "### math/theory fundamentals of deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ed9275-fe77-48a2-b064-0ad2716ec70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32414dac-0a7f-4b24-9c58-19a1f6455142",
   "metadata": {},
   "source": [
    "#### vector/tensor normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e85cc-b74e-4976-86b5-5fcda6b42334",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1.1, 0.2, 0.3, 2.4, 0.2, 0.3, 1.7, 0.4, 0.5, 0.3, 0.8, 0.9])\n",
    "\n",
    "# compute L2 norm\n",
    "v_norm = v / np.linalg.norm(v)\n",
    "print(\"L2 norm:\", v_norm)\n",
    "\n",
    "# check if normalized (allowing small numerical error)\n",
    "if np.isclose(norm, 1.0, 0.1):\n",
    "    print(\"Embedding is L2 normalized\")\n",
    "else:\n",
    "    print(\"Embedding is NOT L2 normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc2d32-a123-44fd-9b0a-52d9ad1b9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = lambda v, p: sum([abs(x)**p for x in v])/p\n",
    "euclideanNorm = lambda v: sum([abs(x)**2 for x in v])/2\n",
    "l1Norm = lambda v: sum([abs(x) for x in v])\n",
    "maxNorm = lambda v: max(v)\n",
    "\n",
    "# norms basically measure the size of a vector, formally L^p\n",
    "# f : V -> (x <= R^+)\n",
    "# eucledian norm (L^2) is simply the euclidean distance from the origin\n",
    "#   to the point identified by x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd5d18-60f8-4e19-9d00-00b4bad9d119",
   "metadata": {},
   "source": [
    "#### useful/important torch ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244d410e-4765-450e-9345-5190f218d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4]),\n",
       " tensor([4, 5, 6, 7, 8, 9]),\n",
       " tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange(start=0, end, step=1)\n",
    "torch.arange(5), torch.arange(4, 10), torch.arange(0, 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33aa80a9-11a5-4bc2-bd84-45e8cbd67688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.empty()\n",
    "torch.empty(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f147dedc-2edd-418e-8383-e394ce4c1a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.9701, -0.9327,  1.0902, -0.4303, -1.6986]),\n",
       " tensor([[ 0.6676, -2.2604],\n",
       "         [ 0.1939, -0.4340]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.randn(*size, *)\n",
    "# rand numbers from a normal distribution with mean 0 and variance 1\n",
    "torch.randn(5), torch.randn(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8ea2fc6-3c47-4322-ae4e-ed81779d79f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 2.,  4.,  6.],\n",
       "        [ 3.,  6.,  9.],\n",
       "        [ 4.,  8., 12.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.outer(input, vec2, *)\n",
    "# an outer product takes 2 vectors and produces a matrix (n x m) if input len is n and vec2 len is m\n",
    "# think of it like you put input on the left vertically and vec2 at the top horizontally and then calc\n",
    "#  the products of each combo of numbers at each matrix position (n_i x m_i)\n",
    "torch.outer(\n",
    "    torch.arange(1., 5.),\n",
    "    torch.arange(1., 4.),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c3f245-dfa2-493e-bab2-362c8e301145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.broadcast_to(input, shape)\n",
    "torch.broadcast_to(\n",
    "    torch.tensor([1, 2, 3]),\n",
    "    (3, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a52f9d2-4f68-444b-ac6b-d0e4eb43793c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.1232e-17+1.0000j, -1.4142e+00-1.4142j], dtype=torch.complex128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.polar(abs, angle, *)\n",
    "# complex tensor whose elements are cartesian coords corresponding to the polar coords with abs and angle\n",
    "torch.polar(\n",
    "    torch.tensor([1, 2], dtype=torch.float64),\n",
    "    torch.tensor([np.pi / 2, 5 * np.pi / 4], dtype=torch.float64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d450d8f-902c-4cd9-8a10-357a6814c988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[69., 69., 69.],\n",
       "        [69., 69., 69.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.full_like(input, fill_value)\n",
    "# copies shape of input and copies fill_value to every pos\n",
    "torch.full_like(\n",
    "    torch.randn(2, 3),\n",
    "    69,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ffab24a-9b7c-46b8-8c9f-92ff53bc8368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.bernoulli(input, *)\n",
    "# get binary random numbers from bernouli dist where each val in input (0, 1) is the probablity of 0 or 1\n",
    "torch.bernoulli(\n",
    "    torch.empty(3, 3).uniform_(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd46c44-7ffa-4164-95c3-2d4dc0d19132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24caabb-c621-49f3-b725-b6cf8c68ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d77a5b50-8e2a-4847-8ad6-ec5da96924c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0096, -0.2896,  0.5056],\n",
       "         [-0.4422, -1.4588, -0.2258]]),\n",
       " tensor([[ 0.0096, -0.2896],\n",
       "         [ 0.5056, -0.4422],\n",
       "         [-1.4588, -0.2258]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.Tensor.view(*shape)\n",
    "# same data diff shape\n",
    "x = torch.randn(2, 3)\n",
    "x, x.view(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8f2b3-3515-4299-8b0e-d7741b84d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.squeeze/unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ab83d12-ee9c-4c42-87b6-2284a08f427b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]),\n",
       " tensor([[0, 1],\n",
       "         [2, 3]]),\n",
       " tensor([[0., 1.],\n",
       "         [2., 3.]]),\n",
       " tensor([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.reshape\n",
    "a = torch.arange(4.)\n",
    "b = torch.tensor([[0, 1], [2, 3]])\n",
    "a, b, torch.reshape(a, (2, 2)), torch.reshape(b, (-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "741c425d-280b-4434-a3cf-514030316a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.]]),\n",
       " tensor([[420.,  69., 420.]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.where(condition, input)\n",
    "torch.where(torch.randn(3, 2) > 0, 1.0, 0.0), torch.where(torch.randn(1, 3) > 0, 69.0, 420.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859448d-be1e-49ad-9f7e-1737842824cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.trapz (trapezoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99f98593-7a33-414f-bf00-d8bbb75179ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000]),\n",
       " tensor([-10.,  -5.,   0.,   5.,  10.]),\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.linspace(start, end, steps, *)\n",
    "# 1d tensor of size steps whose values are evenly spaced from start to end inclusive\n",
    "torch.linspace(3, 10, steps=5), torch.linspace(-10, 10, steps=5), torch.linspace(0, 10, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec4692-59ba-44e8-aace-1db2a8a524bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
